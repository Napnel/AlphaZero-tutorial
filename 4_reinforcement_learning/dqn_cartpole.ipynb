{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "from tensorflow.compat.v1.losses import huber_loss\n",
    "from utils.gpu_memory import limited_gpu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory growth: True\n"
     ]
    }
   ],
   "source": [
    "limited_gpu_memory() # GPUメモリの使用を固定から可変にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = 'CartPole-v0'\n",
    "\n",
    "NUM_EPISODES = 100\n",
    "MAX_STEPS = 200\n",
    "GAMMA = 0.99\n",
    "WARMUP = 10 # 無操作ステップ数\n",
    "\n",
    "# 探索パラメータ\n",
    "E_START = 1.0 # εの初期値\n",
    "E_STOP = 0.01 # εの最終値\n",
    "E_DECAY_RATE = 0.001 # εの減衰率\n",
    "\n",
    "MEMORY_SIZE = 3000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(16, activation='relu', input_dim=num_states))\n",
    "        self.model.add(Dense(16, activation='relu'))\n",
    "        self.model.add(Dense(16, activation='relu'))\n",
    "        self.model.add(Dense(num_actions, activation='linear'))\n",
    "        \n",
    "        self.model.compile(loss=huber_loss, optimizer=Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, memory_size):\n",
    "        self.buffer = deque(maxlen=memory_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.main_qn = QNetwork(num_states, num_actions)\n",
    "        self.target_qn = QNetwork(num_states, num_actions)\n",
    "        print(self.main_qn.model.summary())\n",
    "        \n",
    "        self.memory = ReplayMemory(MEMORY_SIZE)\n",
    "        \n",
    "    def replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        \n",
    "        inputs = np.zeros((BATCH_SIZE, self.num_states))\n",
    "        targets = np.zeros((BATCH_SIZE, self.num_actions))\n",
    "\n",
    "        minibatch =self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        for i, (state_b, action_b, next_state_b, reward_b) in enumerate(minibatch):\n",
    "            inputs[i] = state_b\n",
    "\n",
    "            if not(next_state_b == np.zeros(state_b.shape)).all(axis=1):\n",
    "                target = reward_b + GAMMA * np.amax(self.target_qn.model.predict(next_state_b)[0])\n",
    "            else:\n",
    "                target = reward_b\n",
    "\n",
    "            targets[i] = self.main_qn.model.predict(state_b)\n",
    "            targets[i][action_b] = target\n",
    "\n",
    "        self.main_qn.model.fit(inputs, targets, epochs=1, verbose=0)\n",
    "        \n",
    "    def decide_action(self, state, total_step):\n",
    "        epsilon = E_STOP + (E_START - E_STOP) * np.exp(-E_DECAY_RATE * total_step)\n",
    "        \n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            return np.argmax(self.main_qn.model.predict(state)[0])\n",
    "        \n",
    "        return np.random.choice([0, 1])\n",
    "    \n",
    "    def update_target_q_network(self):\n",
    "        self.target_qn.model.set_weights(self.main_qn.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.brain = Brain(num_states, num_actions)\n",
    "        \n",
    "    def update_q_function(self):\n",
    "        self.brain.replay()\n",
    "        \n",
    "    def get_action(self, state, total_step):\n",
    "        return self.brain.decide_action(state, total_step)\n",
    "    \n",
    "    def memorize(self, state, action, state_next, reward):\n",
    "        self.brain.memory.add((state, action, state_next, reward))\n",
    "        \n",
    "    def update_target_q_function(self):\n",
    "        self.brain.update_target_q_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviroment:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV)\n",
    "        self.num_states = self.env.observation_space.shape[0]\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        self.total_step = 0\n",
    "        self.agent = Agent(self.num_states, self.num_actions)\n",
    "        \n",
    "    def run(self):\n",
    "        success_count = 0\n",
    "        episode_final = False\n",
    "        episode_10_list = np.zeros(10)  # 10試行分の立ち続けたstep数を格納し、平均ステップ数を出力に利用\n",
    "\n",
    "        for episode in range(1, NUM_EPISODES + 1):\n",
    "            start = time.time()\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, (1, self.num_states))\n",
    "            \n",
    "            self.agent.update_target_q_function()\n",
    "            \n",
    "            for step in range(1, MAX_STEPS + 1):\n",
    "                self.total_step += 1\n",
    "                # 行動決定\n",
    "                action = self.agent.get_action(state, self.total_step)\n",
    "\n",
    "                next_state, _, done, _ = self.env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, self.num_states])\n",
    "\n",
    "                if done:\n",
    "                    if step >= 190:\n",
    "                        success_count += 1\n",
    "                        reward = 1\n",
    "                    else:\n",
    "                        success_count = 0 # 連続記録をリセット\n",
    "                        reward = -1\n",
    "\n",
    "                    next_state = np.zeros(next_state.shape)\n",
    "                    episode_10_list = np.hstack((episode_10_list[1:], step + 1))\n",
    "\n",
    "                else:\n",
    "                    reward = 0\n",
    "                \n",
    "                self.agent.memorize(state, action, next_state, reward)\n",
    "                \n",
    "                self.agent.update_q_function()\n",
    "                \n",
    "                state = next_state\n",
    "\n",
    "                # 終了時の処理\n",
    "                if done:\n",
    "                    print(\"{} Episode: Finished after {} steps：10試行の平均step数 = {} time: {}\".format(episode, step, episode_10_list.mean(), time.time() - start))\n",
    "                    break\n",
    "\n",
    "        if success_count >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cartpole_env = Enviroment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Episode: Finished after 16 steps：10試行の平均step数 = 1.7 time: 0.004000186920166016\n",
      "2 Episode: Finished after 19 steps：10試行の平均step数 = 3.7 time: 5.743128776550293\n",
      "3 Episode: Finished after 10 steps：10試行の平均step数 = 4.8 time: 12.633260726928711\n",
      "4 Episode: Finished after 12 steps：10試行の平均step数 = 6.1 time: 15.459732055664062\n",
      "5 Episode: Finished after 11 steps：10試行の平均step数 = 7.3 time: 14.06091833114624\n",
      "6 Episode: Finished after 22 steps：10試行の平均step数 = 9.6 time: 27.78620743751526\n",
      "7 Episode: Finished after 15 steps：10試行の平均step数 = 11.2 time: 19.27648091316223\n",
      "8 Episode: Finished after 15 steps：10試行の平均step数 = 12.8 time: 19.357269525527954\n",
      "9 Episode: Finished after 9 steps：10試行の平均step数 = 13.8 time: 11.361914157867432\n",
      "10 Episode: Finished after 25 steps：10試行の平均step数 = 16.4 time: 31.823806285858154\n",
      "11 Episode: Finished after 18 steps：10試行の平均step数 = 16.6 time: 22.80397129058838\n",
      "12 Episode: Finished after 33 steps：10試行の平均step数 = 18.0 time: 42.33863878250122\n",
      "13 Episode: Finished after 27 steps：10試行の平均step数 = 19.7 time: 35.00179386138916\n",
      "14 Episode: Finished after 41 steps：10試行の平均step数 = 22.6 time: 52.77315664291382\n",
      "15 Episode: Finished after 17 steps：10試行の平均step数 = 23.2 time: 22.76279044151306\n",
      "16 Episode: Finished after 11 steps：10試行の平均step数 = 22.1 time: 14.631079196929932\n",
      "17 Episode: Finished after 60 steps：10試行の平均step数 = 26.6 time: 79.85704040527344\n",
      "18 Episode: Finished after 26 steps：10試行の平均step数 = 27.7 time: 34.42057776451111\n",
      "19 Episode: Finished after 29 steps：10試行の平均step数 = 29.7 time: 39.044548988342285\n",
      "20 Episode: Finished after 42 steps：10試行の平均step数 = 31.4 time: 55.681143045425415\n",
      "21 Episode: Finished after 68 steps：10試行の平均step数 = 36.4 time: 90.81501960754395\n",
      "22 Episode: Finished after 79 steps：10試行の平均step数 = 41.0 time: 106.83100700378418\n",
      "23 Episode: Finished after 119 steps：10試行の平均step数 = 50.2 time: 155.65762448310852\n",
      "24 Episode: Finished after 67 steps：10試行の平均step数 = 52.8 time: 87.65927577018738\n",
      "25 Episode: Finished after 200 steps：10試行の平均step数 = 71.1 time: 268.06258368492126\n",
      "26 Episode: Finished after 139 steps：10試行の平均step数 = 83.9 time: 187.40642046928406\n",
      "27 Episode: Finished after 70 steps：10試行の平均step数 = 84.9 time: 94.90649366378784\n",
      "28 Episode: Finished after 21 steps：10試行の平均step数 = 84.4 time: 28.38778257369995\n",
      "29 Episode: Finished after 48 steps：10試行の平均step数 = 86.3 time: 64.60279583930969\n",
      "30 Episode: Finished after 48 steps：10試行の平均step数 = 86.9 time: 64.70165944099426\n",
      "31 Episode: Finished after 183 steps：10試行の平均step数 = 98.4 time: 247.01703333854675\n",
      "32 Episode: Finished after 200 steps：10試行の平均step数 = 110.5 time: 270.4548108577728\n",
      "33 Episode: Finished after 134 steps：10試行の平均step数 = 112.0 time: 181.56733226776123\n",
      "34 Episode: Finished after 133 steps：10試行の平均step数 = 118.6 time: 183.70388412475586\n",
      "35 Episode: Finished after 152 steps：10試行の平均step数 = 113.8 time: 209.35885620117188\n",
      "36 Episode: Finished after 127 steps：10試行の平均step数 = 112.6 time: 170.68117666244507\n",
      "37 Episode: Finished after 119 steps：10試行の平均step数 = 117.5 time: 157.62875175476074\n",
      "38 Episode: Finished after 177 steps：10試行の平均step数 = 133.1 time: 241.93267107009888\n",
      "39 Episode: Finished after 200 steps：10試行の平均step数 = 148.3 time: 268.49352979660034\n",
      "40 Episode: Finished after 200 steps：10試行の平均step数 = 163.5 time: 277.6720702648163\n",
      "41 Episode: Finished after 153 steps：10試行の平均step数 = 160.5 time: 214.49496340751648\n",
      "42 Episode: Finished after 173 steps：10試行の平均step数 = 157.8 time: 244.09828853607178\n",
      "43 Episode: Finished after 200 steps：10試行の平均step数 = 164.4 time: 281.7154643535614\n",
      "44 Episode: Finished after 200 steps：10試行の平均step数 = 171.1 time: 282.5206370353699\n",
      "45 Episode: Finished after 186 steps：10試行の平均step数 = 174.5 time: 259.5130169391632\n",
      "46 Episode: Finished after 200 steps：10試行の平均step数 = 181.8 time: 276.8165702819824\n",
      "47 Episode: Finished after 200 steps：10試行の平均step数 = 189.9 time: 276.2241973876953\n",
      "48 Episode: Finished after 200 steps：10試行の平均step数 = 192.2 time: 277.22253227233887\n",
      "49 Episode: Finished after 189 steps：10試行の平均step数 = 191.1 time: 261.3229682445526\n",
      "50 Episode: Finished after 200 steps：10試行の平均step数 = 191.1 time: 276.3807702064514\n",
      "51 Episode: Finished after 196 steps：10試行の平均step数 = 195.4 time: 272.823855638504\n",
      "52 Episode: Finished after 200 steps：10試行の平均step数 = 198.1 time: 275.7397139072418\n",
      "53 Episode: Finished after 200 steps：10試行の平均step数 = 198.1 time: 278.20622301101685\n",
      "54 Episode: Finished after 125 steps：10試行の平均step数 = 190.6 time: 172.35021352767944\n",
      "55 Episode: Finished after 200 steps：10試行の平均step数 = 192.0 time: 278.7844603061676\n",
      "56 Episode: Finished after 200 steps：10試行の平均step数 = 192.0 time: 276.58944058418274\n",
      "57 Episode: Finished after 200 steps：10試行の平均step数 = 192.0 time: 276.6636881828308\n",
      "58 Episode: Finished after 200 steps：10試行の平均step数 = 192.0 time: 274.0191459655762\n",
      "59 Episode: Finished after 200 steps：10試行の平均step数 = 193.1 time: 267.93450379371643\n",
      "60 Episode: Finished after 200 steps：10試行の平均step数 = 193.1 time: 266.83711409568787\n"
     ]
    }
   ],
   "source": [
    "cartpole_env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartpole_env.agent.brain.main_qn.model.save_weights('./saved_weight/main_qn')\n",
    "cartpole_env.agent.brain.target_qn.model.save_weights('./saved_weight/target_qn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dl_env': conda)",
   "language": "python",
   "name": "python37664bitdlenvconda4ed1964df216439a8417d0a4f16ce08f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
